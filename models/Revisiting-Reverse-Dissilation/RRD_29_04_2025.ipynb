{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbPIUTjRmGf2",
        "outputId": "a9bd5fa3-67eb-4f0b-a24f-05a0722b7ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone repo and install dependencies"
      ],
      "metadata": {
        "id": "CBcAboogB5Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tientrandinh/Revisiting-Reverse-Distillation.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLHowpNcBPtb",
        "outputId": "e3cfba03-bf41-4f08-f960-691e7aac5c94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Revisiting-Reverse-Distillation'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 129 (delta 15), reused 13 (delta 13), pack-reused 107 (from 1)\u001b[K\n",
            "Receiving objects: 100% (129/129), 2.55 MiB | 5.77 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./Revisiting-Reverse-Distillation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIJ5YKEUB-HK",
        "outputId": "d592b1c3-392a-4466-f59a-4dc7e050fed5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Revisiting-Reverse-Distillation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn0dRiVKnywc",
        "outputId": "e937035d-18f8-4904-90f2-e83431ed53ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geomloss\n",
            "  Downloading geomloss-0.2.6.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from geomloss) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from geomloss) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->geomloss)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->geomloss)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->geomloss)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->geomloss)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->geomloss)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->geomloss)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->geomloss)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->geomloss)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->geomloss)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->geomloss)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->geomloss) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->geomloss) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->geomloss) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: geomloss\n",
            "  Building wheel for geomloss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for geomloss: filename=geomloss-0.2.6-py3-none-any.whl size=32247 sha256=b71af17d1b7f3f975ab877cb19a1d76871826f8b319e44ae62e13c56f9e5e8b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/cf/07/9d1d883feac2951b968fed8ef676842dc90b9860ea49a4dcac\n",
            "Successfully built geomloss\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, geomloss\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed geomloss-0.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install geomloss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPG_AsEuGfu1"
      },
      "source": [
        "## After downloading MVTEC Dataset, unzip and start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ky5gIzBNmHXX"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/Revisiting-Reverse-Distillation/mvtec_anomaly_detection.tar.xz' '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2Vdr7zImHbq"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/mvtec_anomaly_detection.tar.xz\", \"/content/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyHO1aorGCtE"
      },
      "source": [
        "## Start training on MVTEC dataset\n",
        "### Training/testing on 'carpet', 'leather'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load main.py\n",
        "%%writefile main.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import geomloss\n",
        "from fastprogress import progress_bar\n",
        "from argparse import ArgumentParser\n",
        "from model.resnet import resnet18, resnet34, resnet50, wide_resnet50_2\n",
        "from model.de_resnet import de_resnet18, de_resnet34, de_wide_resnet50_2, de_resnet50\n",
        "from utils.utils_test import evaluation_multi_proj\n",
        "from utils.utils_train import MultiProjectionLayer, Revisit_RDLoss, loss_fucntion\n",
        "from dataset.dataset import MVTecDataset_test, MVTecDataset_train, get_data_transforms\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_args():\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument('--save_folder', default = './RD++_checkpoint_result', type=str)\n",
        "    parser.add_argument('--batch_size', default = 16, type=int)\n",
        "    parser.add_argument('--image_size', default = 256, type=int)\n",
        "    parser.add_argument('--detail_training', default='note', type = str)\n",
        "    parser.add_argument('--proj_lr', default = 0.001, type=float)\n",
        "    parser.add_argument('--distill_lr', default = 0.005, type=float)\n",
        "    parser.add_argument('--weight_proj', default = 0.2, type=float)\n",
        "    parser.add_argument('--classes', nargs=\"+\", default=[\"carpet\", \"leather\"])\n",
        "    pars = parser.parse_args()\n",
        "    return pars\n",
        "\n",
        "def train(_class_, pars):\n",
        "    print(_class_)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    data_transform, gt_transform = get_data_transforms(pars.image_size, pars.image_size)\n",
        "\n",
        "    train_path = '/content/drive/MyDrive/Revisiting-Reverse-Distillation/mvtec_anomaly_detection/' + _class_ + '/train'\n",
        "    test_path = '/content/drive/MyDrive/Revisiting-Reverse-Distillation/mvtec_anomaly_detection/' + _class_\n",
        "\n",
        "    if not os.path.exists(pars.save_folder + '/' + _class_):\n",
        "        os.makedirs(pars.save_folder + '/' + _class_)\n",
        "    save_model_path  = pars.save_folder + '/' + _class_ + '/' + 'wres50_'+_class_+'.pth'\n",
        "    train_data = MVTecDataset_train(root=train_path, transform=data_transform)\n",
        "    test_data = MVTecDataset_test(root=test_path, transform=data_transform, gt_transform=gt_transform)\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=pars.batch_size, shuffle=True)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Use pretrained ImageNet for encoder\n",
        "    encoder, bn = wide_resnet50_2(pretrained=True)\n",
        "    encoder = encoder.to(device)\n",
        "    bn = bn.to(device)\n",
        "    encoder.eval()\n",
        "\n",
        "    decoder = de_wide_resnet50_2(pretrained=False)\n",
        "    decoder = decoder.to(device)\n",
        "\n",
        "    proj_layer =  MultiProjectionLayer(base=64).to(device)\n",
        "    proj_loss = Revisit_RDLoss()\n",
        "    optimizer_proj = torch.optim.Adam(list(proj_layer.parameters()), lr=pars.proj_lr, betas=(0.5,0.999))\n",
        "    optimizer_distill = torch.optim.Adam(list(decoder.parameters())+list(bn.parameters()), lr=pars.distill_lr, betas=(0.5,0.999))\n",
        "\n",
        "\n",
        "    best_score = 0\n",
        "    best_epoch = 0\n",
        "    best_auroc_px = 0\n",
        "    best_auroc_sp = 0\n",
        "    best_aupro_px = 0\n",
        "\n",
        "    auroc_px_list = []\n",
        "    auroc_sp_list = []\n",
        "    aupro_px_list = []\n",
        "\n",
        "    loss_proj = []\n",
        "    loss_distill = []\n",
        "    total_loss = []\n",
        "\n",
        "    history_infor = {}\n",
        "\n",
        "\n",
        "    # set appropriate epochs for specific classes (Some classes converge faster than others)\n",
        "\n",
        "    if _class_ in ['wood']:\n",
        "        # num_epoch = 100\n",
        "        num_epoch = 11\n",
        "\n",
        "    print(f'with class {_class_}, Training with {num_epoch} Epoch')\n",
        "\n",
        "    for epoch in tqdm(range(1,num_epoch+1)):\n",
        "        bn.train()\n",
        "        proj_layer.train()\n",
        "        decoder.train()\n",
        "        loss_proj_running = 0\n",
        "        loss_distill_running = 0\n",
        "        total_loss_running = 0\n",
        "\n",
        "        ## gradient acc\n",
        "        accumulation_steps = 2\n",
        "\n",
        "        for i, (img,img_noise,_) in enumerate(train_dataloader):\n",
        "            img = img.to(device)\n",
        "            img_noise = img_noise.to(device)\n",
        "            inputs = encoder(img)\n",
        "            inputs_noise = encoder(img_noise)\n",
        "\n",
        "            (feature_space_noise, feature_space) = proj_layer(inputs, features_noise = inputs_noise)\n",
        "\n",
        "            L_proj = proj_loss(inputs_noise, feature_space_noise, feature_space)\n",
        "\n",
        "            outputs = decoder(bn(feature_space))#bn(inputs))\n",
        "            L_distill = loss_fucntion(inputs, outputs)\n",
        "            loss = L_distill + pars.weight_proj * L_proj\n",
        "            loss.backward()\n",
        "            if (i + 1) % accumulation_steps == 0:\n",
        "                optimizer_proj.step()\n",
        "                optimizer_distill.step()\n",
        "                # Clear gradients\n",
        "                optimizer_proj.zero_grad()\n",
        "                optimizer_distill.zero_grad()\n",
        "\n",
        "            total_loss_running += loss.detach().cpu().item()\n",
        "            loss_proj_running += L_proj.detach().cpu().item()\n",
        "            loss_distill_running += L_distill.detach().cpu().item()\n",
        "\n",
        "\n",
        "        auroc_px, auroc_sp, aupro_px = evaluation_multi_proj(encoder, proj_layer, bn, decoder, test_dataloader, device)\n",
        "        auroc_px_list.append(auroc_px)\n",
        "        auroc_sp_list.append(auroc_sp)\n",
        "        aupro_px_list.append(aupro_px)\n",
        "        loss_proj.append(loss_proj_running)\n",
        "        loss_distill.append(loss_distill_running)\n",
        "        total_loss.append(total_loss_running)\n",
        "\n",
        "\n",
        "        figure = plt.gcf() # get current figure\n",
        "        figure.set_size_inches(8, 12)\n",
        "        fig, ax = plt.subplots(3,2, figsize = (8, 12))\n",
        "        ax[0][0].plot(auroc_px_list)\n",
        "        ax[0][0].set_title('auroc_px')\n",
        "        ax[0][1].plot(auroc_sp_list)\n",
        "        ax[0][1].set_title('auroc_sp')\n",
        "        ax[1][0].plot(aupro_px_list)\n",
        "        ax[1][0].set_title('aupro_px')\n",
        "        ax[1][1].plot(loss_proj)\n",
        "        ax[1][1].set_title('loss_proj')\n",
        "        ax[2][0].plot(loss_distill)\n",
        "        ax[2][0].set_title('loss_distill')\n",
        "        ax[2][1].plot(total_loss)\n",
        "        ax[2][1].set_title('total_loss')\n",
        "        plt.savefig(pars.save_folder + '/' + _class_ + '/monitor_traning.jpg', dpi = 100)\n",
        "\n",
        "\n",
        "        print('Epoch {}, Sample Auroc: {:.4f}, Pixel Auroc:{:.4f}, Pixel Aupro: {:.4f}'.format(epoch, auroc_sp, auroc_px, aupro_px))\n",
        "\n",
        "\n",
        "        if (auroc_px + auroc_sp + aupro_px) / 3 > best_score:\n",
        "            best_score = (auroc_px + auroc_sp + aupro_px) / 3\n",
        "\n",
        "            best_auroc_px = auroc_px\n",
        "            best_auroc_sp = auroc_sp\n",
        "            best_aupro_px = aupro_px\n",
        "            best_epoch = epoch\n",
        "\n",
        "            torch.save({'proj': proj_layer.state_dict(),\n",
        "                       'decoder': decoder.state_dict(),\n",
        "                        'bn':bn.state_dict()}, save_model_path)\n",
        "\n",
        "            history_infor['auroc_sp'] = best_auroc_sp\n",
        "            history_infor['auroc_px'] = best_auroc_px\n",
        "            history_infor['aupro_px'] = best_aupro_px\n",
        "            history_infor['epoch'] = best_epoch\n",
        "            with open(os.path.join(pars.save_folder + '/' + _class_, f'history.json'), 'w') as f:\n",
        "                json.dump(history_infor, f)\n",
        "    return best_auroc_sp, best_auroc_px, best_aupro_px\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pars = get_args()\n",
        "    print('Training with classes: ', pars.classes)\n",
        "    all_classes = ['wood']\n",
        "    setup_seed(111)\n",
        "    metrics = {'class': [], 'AUROC_sample':[], 'AUROC_pixel': [], 'AUPRO_pixel': []}\n",
        "\n",
        "    # train all_classes\n",
        "    # for c in all_classes\n",
        "    for c in pars.classes:\n",
        "        auroc_sp, auroc_px, aupro_px = train(c, pars)\n",
        "        print('Best score of class: {}, Auroc sample: {:.4f}, Auroc pixel:{:.4f}, Pixel Aupro: {:.4f}'.format(c, auroc_sp, auroc_px, aupro_px))\n",
        "        metrics['class'].append(c)\n",
        "        metrics['AUROC_sample'].append(auroc_sp)\n",
        "        metrics['AUROC_pixel'].append(auroc_px)\n",
        "        metrics['AUPRO_pixel'].append(aupro_px)\n",
        "        pd.DataFrame(metrics).to_csv(f'{pars.save_folder}/metrics_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "_mjyC75a5MVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b0ffbd-d735-458e-fe80-f963122d38bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load dataset/dataset.py\n",
        "%%writefile dataset/dataset.py\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import glob\n",
        "import numpy as np\n",
        "from dataset.noise import Simplex_CLASS\n",
        "import cv2\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, image):\n",
        "        try:\n",
        "            image = torch.from_numpy(image.transpose(2, 0,1))\n",
        "        except:\n",
        "            print('Invalid_transpose, please make sure images have shape (H, W, C) before transposing')\n",
        "        if not isinstance(image, torch.FloatTensor):\n",
        "            image = image.float()\n",
        "        return image\n",
        "\n",
        "\n",
        "class Normalize(object):\n",
        "    \"\"\"\n",
        "    Only normalize images\n",
        "    \"\"\"\n",
        "    def __init__(self, mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]):\n",
        "        self.mean = np.array(mean)\n",
        "        self.std = np.array(std)\n",
        "    def __call__(self, image):\n",
        "        image = (image - self.mean) / self.std\n",
        "        return image\n",
        "\n",
        "def get_data_transforms(size, isize):\n",
        "    data_transforms = transforms.Compose([Normalize(),\\\n",
        "                    ToTensor()])\n",
        "    gt_transforms = transforms.Compose([\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.ToTensor()])\n",
        "    return data_transforms, gt_transforms\n",
        "\n",
        "\n",
        "\n",
        "class MVTecDataset_train(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "        self.img_path = root\n",
        "        self.simplexNoise = Simplex_CLASS()\n",
        "        self.transform = transform\n",
        "        # load dataset\n",
        "        self.img_paths = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "\n",
        "    def load_dataset(self):\n",
        "        img_paths = glob.glob(os.path.join(self.img_path, 'good') + \"/*.jpg\")\n",
        "        return img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img= cv2.resize(img/255., (256, 256))\n",
        "        ## Normal\n",
        "        img_normal = self.transform(img)\n",
        "        ## simplex_noise\n",
        "        size = 256\n",
        "        h_noise = np.random.randint(10, int(size//8))\n",
        "        w_noise = np.random.randint(10, int(size//8))\n",
        "        start_h_noise = np.random.randint(1, size - h_noise)\n",
        "        start_w_noise = np.random.randint(1, size - w_noise)\n",
        "        noise_size = (h_noise, w_noise)\n",
        "        simplex_noise = self.simplexNoise.rand_3d_octaves((3, *noise_size), 6, 0.6)\n",
        "        init_zero = np.zeros((256,256,3))\n",
        "        init_zero[start_h_noise: start_h_noise + h_noise, start_w_noise: start_w_noise+w_noise, :] = 0.2 * simplex_noise.transpose(1,2,0)\n",
        "        img_noise = img + init_zero\n",
        "        img_noise = self.transform(img_noise)\n",
        "        return img_normal,img_noise,img_path.split('/')[-1]\n",
        "\n",
        "\n",
        "class MVTecDataset_test(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform, gt_transform):\n",
        "        self.img_path = os.path.join(root, 'test')\n",
        "        self.gt_path = os.path.join(root, 'ground_truth')\n",
        "        self.simplexNoise = Simplex_CLASS()\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "        # load dataset\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        gt_tot_paths = []\n",
        "        tot_labels = []\n",
        "        tot_types = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.jpg\")\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend([0] * len(img_paths))\n",
        "                tot_labels.extend([0] * len(img_paths))\n",
        "                tot_types.extend(['good'] * len(img_paths))\n",
        "            else:\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.jpg\")\n",
        "                gt_paths = glob.glob(os.path.join(self.gt_path, defect_type) + \"/*.jpg\")\n",
        "                img_paths.sort()\n",
        "                gt_paths.sort()\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend(gt_paths)\n",
        "                tot_labels.extend([1] * len(img_paths))\n",
        "                tot_types.extend([defect_type] * len(img_paths))\n",
        "\n",
        "        assert len(img_tot_paths) == len(gt_tot_paths), \"Something wrong with test and ground truth pair!\"\n",
        "\n",
        "        return img_tot_paths, gt_tot_paths, tot_labels, tot_types\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img= cv2.resize(img/255., (256, 256))\n",
        "        ## Normal\n",
        "        img = self.transform(img)\n",
        "        ## simplex_noise\n",
        "\n",
        "        if gt == 0:\n",
        "            gt = torch.zeros([1, img.shape[-1], img.shape[-1]])\n",
        "        else:\n",
        "            gt = Image.open(gt)\n",
        "            gt = self.gt_transform(gt)\n",
        "\n",
        "        assert img.shape[1:] == gt.shape[1:], \"image.size != gt.size !!!\"\n",
        "\n",
        "        return (img, gt, label, img_type, img_path.split('/')[-1])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRHNeVkv8rG2",
        "outputId": "6d9bc9bd-9b6b-43a8-fbd5-ccdc63e88070"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataset/dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf RD++"
      ],
      "metadata": {
        "id": "8oZCLf-nCE6u"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --save_folder RD++ \\\n",
        "                --classes wood"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eC2J9NFn2kM",
        "outputId": "2ba1dce5-61c7-4f4a-a6e5-8358d7f19928"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with classes:  ['wood']\n",
            "wood\n",
            "with class wood, Training with 11 Epoch\n",
            "  0% 0/11 [00:00<?, ?it/s]Epoch 1, Sample Auroc: 0.5239, Pixel Auroc:0.6563, Pixel Aupro: 0.2411\n",
            "  9% 1/11 [01:00<10:00, 60.08s/it]Epoch 2, Sample Auroc: 0.8588, Pixel Auroc:0.7678, Pixel Aupro: 0.5442\n",
            " 18% 2/11 [01:59<08:57, 59.72s/it]Epoch 3, Sample Auroc: 0.8431, Pixel Auroc:0.7834, Pixel Aupro: 0.5336\n",
            " 27% 3/11 [03:05<08:21, 62.70s/it]Epoch 4, Sample Auroc: 0.8594, Pixel Auroc:0.9166, Pixel Aupro: 0.7383\n",
            " 36% 4/11 [04:03<07:04, 60.66s/it]Epoch 5, Sample Auroc: 0.9020, Pixel Auroc:0.9524, Pixel Aupro: 0.8192\n",
            " 45% 5/11 [05:11<06:20, 63.41s/it]Epoch 6, Sample Auroc: 0.9117, Pixel Auroc:0.9546, Pixel Aupro: 0.8240\n",
            " 55% 6/11 [06:18<05:22, 64.51s/it]Epoch 7, Sample Auroc: 0.9119, Pixel Auroc:0.9515, Pixel Aupro: 0.8158\n",
            " 64% 7/11 [07:23<04:18, 64.75s/it]Epoch 8, Sample Auroc: 0.9113, Pixel Auroc:0.9527, Pixel Aupro: 0.8177\n",
            " 73% 8/11 [08:20<03:06, 62.21s/it]Epoch 9, Sample Auroc: 0.9165, Pixel Auroc:0.9530, Pixel Aupro: 0.8181\n",
            " 82% 9/11 [09:17<02:01, 60.67s/it]Epoch 10, Sample Auroc: 0.9173, Pixel Auroc:0.9531, Pixel Aupro: 0.8181\n",
            " 91% 10/11 [10:13<00:59, 59.27s/it]Epoch 11, Sample Auroc: 0.9201, Pixel Auroc:0.9525, Pixel Aupro: 0.8181\n",
            "100% 11/11 [11:12<00:00, 61.11s/it]\n",
            "Best score of class: wood, Auroc sample: 0.9201, Auroc pixel:0.9525, Pixel Aupro: 0.8181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing with the checkpoints"
      ],
      "metadata": {
        "id": "pmOtSCGFGagB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %load inference.py\n",
        "%%writefile inference.py\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from argparse import ArgumentParser\n",
        "from model.resnet import wide_resnet50_2\n",
        "from model.de_resnet import de_wide_resnet50_2\n",
        "from utils.utils_test import evaluation_multi_proj\n",
        "from utils.utils_train import MultiProjectionLayer\n",
        "from dataset.dataset import MVTecDataset_test, get_data_transforms\n",
        "\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_args():\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument('--checkpoint_folder', default = './your_checkpoint_folder', type=str)\n",
        "    parser.add_argument('--image_size', default = 256, type=int)\n",
        "    parser.add_argument('--classes', nargs=\"+\", default=[\"wood\"])\n",
        "    pars = parser.parse_args()\n",
        "    return pars\n",
        "\n",
        "def inference(_class_, pars):\n",
        "    if not os.path.exists(pars.checkpoint_folder):\n",
        "        os.makedirs(pars.checkpoint_folder)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    data_transform, gt_transform = get_data_transforms(pars.image_size, pars.image_size)\n",
        "\n",
        "    test_path = '/content/drive/MyDrive/Revisiting-Reverse-Distillation/mvtec_anomaly_detection/' + _class_\n",
        "\n",
        "    checkpoint_class  = pars.checkpoint_folder + '/' + _class_ + '/' + 'wres50_'+_class_+'.pth'\n",
        "    test_data = MVTecDataset_test(root=test_path, transform=data_transform, gt_transform=gt_transform)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Use pretrained wide_resnet50 for encoder\n",
        "    encoder, bn = wide_resnet50_2(pretrained=True)\n",
        "    encoder = encoder.to(device)\n",
        "\n",
        "    bn = bn.to(device)\n",
        "    decoder = de_wide_resnet50_2(pretrained=False)\n",
        "    decoder = decoder.to(device)\n",
        "    proj_layer =  MultiProjectionLayer(base=64).to(device)\n",
        "    # Load trained weights for projection layer, bn (OCBE), decoder (student)\n",
        "    checkpoint_class  = pars.checkpoint_folder + '/' + _class_ + '/' + 'wres50_'+_class_+'.pth'\n",
        "    ckp = torch.load(checkpoint_class, map_location='cpu')\n",
        "    proj_layer.load_state_dict(ckp['proj'])\n",
        "    bn.load_state_dict(ckp['bn'])\n",
        "    decoder.load_state_dict(ckp['decoder'])\n",
        "\n",
        "    auroc_px, auroc_sp, aupro_px = evaluation_multi_proj(encoder, proj_layer, bn, decoder, test_dataloader, device)\n",
        "    print('{}: Sample Auroc: {:.4f}, Pixel Auroc:{:.4f}, Pixel Aupro: {:.4f}'.format(_class_, auroc_sp, auroc_px, aupro_px))\n",
        "    return auroc_sp, auroc_px, aupro_px\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pars = get_args()\n",
        "\n",
        "    item_list = [ 'wood']\n",
        "    setup_seed(111)\n",
        "    metrics = {'class': [], 'AUROC_sample':[], 'AUROC_pixel': [], 'AUPRO_pixel': []}\n",
        "\n",
        "    for c in pars.classes:\n",
        "        auroc_sp, auroc_px, aupro_px = inference(c, pars)\n",
        "        metrics['class'].append(c)\n",
        "        metrics['AUROC_sample'].append(auroc_sp)\n",
        "        metrics['AUROC_pixel'].append(auroc_px)\n",
        "        metrics['AUPRO_pixel'].append(aupro_px)\n",
        "        metrics_df = pd.DataFrame(metrics)\n",
        "        metrics_df.to_csv(f'{pars.checkpoint_folder}/metrics_checkpoints.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HMDCR0EE6ld",
        "outputId": "5ed9c9e2-678d-4d44-f06a-941f2041a32e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting inference.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --checkpoint_folder RD++ \\\n",
        "                     --classes wood"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV9vPBz5oZWj",
        "outputId": "be50a14e-1f43-424a-c639-3380a39a03e8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wood: Sample Auroc: 0.9201, Pixel Auroc:0.9525, Pixel Aupro: 0.8181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6F_DQSCmIAy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}