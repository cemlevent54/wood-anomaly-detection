{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Google Drive Bağlantısı**"
      ],
      "metadata": {
        "id": "--_PW5zUQUAD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek7JrrKdQNws",
        "outputId": "5d1811eb-4c6b-46fe-f7de-afc7fcc4f5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "fbhL5_3wR31H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd dinomaly_11_04_2025"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7hHaatFQYR-",
        "outputId": "f3ded078-7ae9-42a3-a749-a88843a6dce3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dinomaly_11_04_2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/guojiajeremy/Dinomaly.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkdduGydQsTy",
        "outputId": "c1cd13e5-d93c-4dc3-f4e0-2ca73d015668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dinomaly'...\n",
            "remote: Enumerating objects: 286, done.\u001b[K\n",
            "remote: Counting objects: 100% (286/286), done.\u001b[K\n",
            "remote: Compressing objects: 100% (215/215), done.\u001b[K\n",
            "remote: Total 286 (delta 86), reused 256 (delta 66), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (286/286), 353.19 KiB | 1.30 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "Updating files: 100% (196/196), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Dinomaly"
      ],
      "metadata": {
        "id": "ulb2eQILSm_0",
        "outputId": "da5eabee-ea98-424c-cbe2-89a648a9441b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dinomaly_11_04_2025/Dinomaly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Miniconda'yı indirip kur\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# Conda'nın Colab ortamına eklenmesi\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.10/site-packages')\n",
        "\n",
        "# Conda versiyonunu kontrol et\n",
        "!conda --version"
      ],
      "metadata": {
        "id": "iHsXFDDdSpGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe5257d-6e82-48bc-fc36-06b54f10e675"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-14 11:25:31--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154615621 (147M) [application/octet-stream]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>] 147.45M  70.0MB/s    in 2.1s    \n",
            "\n",
            "2025-04-14 11:25:33 (70.0 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [154615621/154615621]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "conda 25.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n my_env python=3.8.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kX-RPcsTqWe",
        "outputId": "2aadec92-4753-4148-cccf-ad5e66ca4c8f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 25.1.1\n",
            "    latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/my_env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.8.12\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2025.2.25  |       h06a4308_0         129 KB\n",
            "    libffi-3.3                 |       he6710b0_2          50 KB\n",
            "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
            "    pip-24.2                   |   py38h06a4308_0         2.2 MB\n",
            "    python-3.8.12              |       h12debd9_0        18.3 MB\n",
            "    setuptools-75.1.0          |   py38h06a4308_0         1.7 MB\n",
            "    wheel-0.44.0               |   py38h06a4308_0         108 KB\n",
            "    xz-5.6.4                   |       h5eee18b_1         567 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        26.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.2.25-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0 \n",
            "  pip                pkgs/main/linux-64::pip-24.2-py38h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.8.12-h12debd9_0 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-75.1.0-py38h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.8.12        | 18.3 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "openssl-1.1.1w       | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-24.2             | 2.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "setuptools-75.1.0    | 1.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "xz-5.6.4             | 567 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 129 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-1.1.1w       | 3.7 MB    | :   0% 0.004187193943698291/1 [00:00<00:25, 25.45s/it]\u001b[A\n",
            "\n",
            "\n",
            "python-3.8.12        | 18.3 MB   | :   0% 0.000855561223671871/1 [00:00<02:14, 134.39s/it]\n",
            "\n",
            "pip-24.2             | 2.2 MB    | :   1% 0.007073190948525958/1 [00:00<00:15, 15.73s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "xz-5.6.4             | 567 KB    | :   3% 0.028233137059266496/1 [00:00<00:03,  3.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  1.75it/s]                \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 129 KB    | :  12% 0.12381823265796574/1 [00:00<00:01,  1.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 129 KB    | : 100% 1.0/1 [00:00<00:00,  1.28s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | :  15% 0.14783134378186213/1 [00:00<00:01,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  1.26s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "python-3.8.12        | 18.3 MB   | :   4% 0.03593357139421858/1 [00:00<00:04,  5.06s/it]  \n",
            "\n",
            "pip-24.2             | 2.2 MB    | :  30% 0.29707401983809023/1 [00:00<00:00,  1.65it/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | :  32% 0.3178705158799449/1 [00:00<00:00,  1.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00,  1.50it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:00<00:00,  5.31it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:00<00:00,  5.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.12        | 18.3 MB   | :  23% 0.2335682140624208/1 [00:00<00:00,  1.07s/it] \n",
            "\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  3.54it/s]                \u001b[A\u001b[A\n",
            "\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  3.54it/s]\u001b[A\u001b[A\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  2.81it/s]                \u001b[A\n",
            "python-3.8.12        | 18.3 MB   | :  57% 0.5689482137417942/1 [00:00<00:00,  1.84it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  2.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  2.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00,  2.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00,  2.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "python-3.8.12        | 18.3 MB   | : 100% 1.0/1 [00:00<00:00,  1.35it/s]\n",
            "\n",
            "\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.30s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.30s/it]\u001b[A\u001b[A\u001b[A\n",
            "openssl-1.1.1w       | 3.7 MB    | : 100% 1.0/1 [00:01<00:00,  2.81it/s]\u001b[A\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate my_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n my_env python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pChgysaT4S2",
        "outputId": "370b63d5-a095-439a-9f2c-9932aabbbc70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n my_env pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJwsjpbwUDhV",
        "outputId": "ceacae87-1a13-461c-8a93-b4d0e43f87a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting matplotlib==3.2.1 (from -r requirements.txt (line 3))\n",
            "  Downloading matplotlib-3.2.1-cp38-cp38-manylinux1_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting numpy==1.18.4 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.18.4-cp38-cp38-manylinux1_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting opencv_python_headless==4.6.0.66 (from -r requirements.txt (line 5))\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pandas==1.3.5 (from -r requirements.txt (line 6))\n",
            "  Downloading pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting Pillow==9.0.1 (from -r requirements.txt (line 7))\n",
            "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting scikit_image==0.19.3 (from -r requirements.txt (line 8))\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting scikit_learn==0.22.2.post1 (from -r requirements.txt (line 9))\n",
            "  Downloading scikit_learn-0.22.2.post1-cp38-cp38-manylinux1_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting scipy==1.4.1 (from -r requirements.txt (line 10))\n",
            "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting tabulate==0.9.0 (from -r requirements.txt (line 11))\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting torch==1.12.0+cu113 (from -r requirements.txt (line 12))\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1837.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 GB 12.4 MB/s eta 0:00:00\n",
            "Collecting torchvision==0.13.0+cu113 (from -r requirements.txt (line 13))\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp38-cp38-linux_x86_64.whl (23.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.4/23.4 MB 43.0 MB/s eta 0:00:00\n",
            "Collecting tqdm==4.64.1 (from -r requirements.txt (line 14))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n",
            "Collecting ptflops==0.7 (from -r requirements.txt (line 15))\n",
            "  Downloading ptflops-0.7.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting timm==0.9.12 (from -r requirements.txt (line 16))\n",
            "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.2.1->-r requirements.txt (line 3))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.2.1->-r requirements.txt (line 3))\n",
            "  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib==3.2.1->-r requirements.txt (line 3))\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil>=2.1 (from matplotlib==3.2.1->-r requirements.txt (line 3))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2017.3 (from pandas==1.3.5->-r requirements.txt (line 6))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting networkx>=2.2 (from scikit_image==0.19.3->-r requirements.txt (line 8))\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 66.6 MB/s eta 0:00:00\n",
            "Collecting imageio>=2.4.1 (from scikit_image==0.19.3->-r requirements.txt (line 8))\n",
            "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tifffile>=2019.7.26 (from scikit_image==0.19.3->-r requirements.txt (line 8))\n",
            "  Downloading tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from scikit_image==0.19.3->-r requirements.txt (line 8))\n",
            "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting packaging>=20.0 (from scikit_image==0.19.3->-r requirements.txt (line 8))\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting joblib>=0.11 (from scikit_learn==0.22.2.post1->-r requirements.txt (line 9))\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting typing-extensions (from torch==1.12.0+cu113->-r requirements.txt (line 12))\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests (from torchvision==0.13.0+cu113->-r requirements.txt (line 13))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pyyaml (from timm==0.9.12->-r requirements.txt (line 16))\n",
            "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting huggingface-hub (from timm==0.9.12->-r requirements.txt (line 16))\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors (from timm==0.9.12->-r requirements.txt (line 16))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting networkx>=2.2 (from scikit_image==0.19.3->-r requirements.txt (line 8))\n",
            "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.1->matplotlib==3.2.1->-r requirements.txt (line 3))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting filelock (from huggingface-hub->timm==0.9.12->-r requirements.txt (line 16))\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub->timm==0.9.12->-r requirements.txt (line 16))\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 13))\n",
            "  Downloading charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 13))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 13))\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchvision==0.13.0+cu113->-r requirements.txt (line 13))\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading matplotlib-3.2.1-cp38-cp38-manylinux1_x86_64.whl (12.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 129.1 MB/s eta 0:00:00\n",
            "Downloading numpy-1.18.4-cp38-cp38-manylinux1_x86_64.whl (20.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.7/20.7 MB 170.9 MB/s eta 0:00:00\n",
            "Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.3/48.3 MB 44.9 MB/s eta 0:00:00\n",
            "Downloading pandas-1.3.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.5/11.5 MB 134.5 MB/s eta 0:00:00\n",
            "Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 101.5 MB/s eta 0:00:00\n",
            "Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.0/14.0 MB 125.1 MB/s eta 0:00:00\n",
            "Downloading scikit_learn-0.22.2.post1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 26.6 MB/s eta 0:00:00\n",
            "Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.0/26.0 MB 47.1 MB/s eta 0:00:00\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 78.1 MB/s eta 0:00:00\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 44.2 MB/s eta 0:00:00\n",
            "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 75.3 MB/s eta 0:00:00\n",
            "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 122.4 MB/s eta 0:00:00\n",
            "Downloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
            "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 746.5/746.5 kB 34.4 MB/s eta 0:00:00\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Downloading charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py): started\n",
            "  Building wheel for ptflops (setup.py): finished with status 'done'\n",
            "  Created wheel for ptflops: filename=ptflops-0.7-py3-none-any.whl size=11075 sha256=01d0959e44790a7672b6184b1aaf6c83de813f2e1f3de322f91b49c79994b6fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/40/d0/09d56cf656f251c7f7e9879f0b87b4e6852b3c65ba3f5ba184\n",
            "Successfully built ptflops\n",
            "Installing collected packages: pytz, urllib3, typing-extensions, tqdm, tabulate, six, safetensors, pyyaml, pyparsing, Pillow, packaging, numpy, networkx, kiwisolver, joblib, idna, fsspec, filelock, cycler, charset-normalizer, certifi, torch, tifffile, scipy, requests, PyWavelets, python-dateutil, opencv_python_headless, imageio, torchvision, scikit_learn, scikit_image, ptflops, pandas, matplotlib, huggingface-hub, timm\n",
            "Successfully installed Pillow-9.0.1 PyWavelets-1.4.1 certifi-2025.1.31 charset-normalizer-3.4.1 cycler-0.12.1 filelock-3.16.1 fsspec-2025.3.0 huggingface-hub-0.30.2 idna-3.10 imageio-2.35.1 joblib-1.4.2 kiwisolver-1.4.7 matplotlib-3.2.1 networkx-3.1 numpy-1.18.4 opencv_python_headless-4.6.0.66 packaging-24.2 pandas-1.3.5 ptflops-0.7 pyparsing-3.1.4 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.3 safetensors-0.5.3 scikit_image-0.19.3 scikit_learn-0.22.2.post1 scipy-1.4.1 six-1.17.0 tabulate-0.9.0 tifffile-2023.7.10 timm-0.9.12 torch-1.12.0+cu113 torchvision-0.13.0+cu113 tqdm-4.64.1 typing-extensions-4.13.2 urllib3-2.2.3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n my_env pip install matplotlib matplotlib_inline xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WACqzTo-VVCH",
        "outputId": "0a174757-68ac-4432-fef4-21be959e77f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/envs/my_env/lib/python3.8/site-packages (3.2.1)\n",
            "Collecting matplotlib_inline\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.28.post1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/my_env/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/envs/my_env/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/envs/my_env/lib/python3.8/site-packages (from matplotlib) (1.18.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/envs/my_env/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/envs/my_env/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting traitlets (from matplotlib_inline)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting torch==2.4.1 (from xformers)\n",
            "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/my_env/lib/python3.8/site-packages (from torch==2.4.1->xformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/envs/my_env/lib/python3.8/site-packages (from torch==2.4.1->xformers) (4.13.2)\n",
            "Collecting sympy (from torch==2.4.1->xformers)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/my_env/lib/python3.8/site-packages (from torch==2.4.1->xformers) (3.1)\n",
            "Collecting jinja2 (from torch==2.4.1->xformers)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/envs/my_env/lib/python3.8/site-packages (from torch==2.4.1->xformers) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1->xformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1->xformers)\n",
            "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->xformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/my_env/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib) (1.17.0)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.1->xformers)\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1->xformers)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading xformers-0.0.28.post1-cp38-cp38-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.7/16.7 MB 37.7 MB/s eta 0:00:00\n",
            "Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 797.1/797.1 MB 30.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 35.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 171.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 174.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 44.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 36.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 65.6 MB/s eta 0:00:00\n",
            "Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 51.4 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 55.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 52.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 46.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.4/209.4 MB 43.1 MB/s eta 0:00:00\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 60.9 MB/s eta 0:00:00\n",
            "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 21.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.3/39.3 MB 38.5 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, triton, traitlets, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, MarkupSafe, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib_inline, jinja2, nvidia-cusolver-cu12, torch, xformers\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "Successfully installed MarkupSafe-2.1.5 jinja2-3.1.6 matplotlib_inline-0.1.7 mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 traitlets-5.14.3 triton-3.0.0 xformers-0.0.28.post1\n",
            "\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 2.4.1 which is incompatible.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n my_env pip install ipython colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7csqw3QW-ib",
        "outputId": "0251adf4-5ac8-4000-9f39-56e161745ee0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython\n",
            "  Downloading ipython-8.12.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting backcall (from ipython)\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting decorator (from ipython)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/envs/my_env/lib/python3.8/site-packages (from ipython) (0.1.7)\n",
            "Collecting pickleshare (from ipython)\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 (from ipython)\n",
            "  Downloading prompt_toolkit-3.0.50-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack-data (from ipython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/envs/my_env/lib/python3.8/site-packages (from ipython) (5.14.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/my_env/lib/python3.8/site-packages (from ipython) (4.13.2)\n",
            "Collecting pexpect>4.3 (from ipython)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack-data->ipython)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 798.3/798.3 kB 22.1 MB/s eta 0:00:00\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 53.5 MB/s eta 0:00:00\n",
            "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "Downloading prompt_toolkit-3.0.50-py3-none-any.whl (387 kB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 63.9 MB/s eta 0:00:00\n",
            "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, pickleshare, backcall, pygments, prompt-toolkit, pexpect, parso, executing, decorator, colorama, asttokens, stack-data, jedi, ipython\n",
            "Successfully installed asttokens-3.0.0 backcall-0.2.0 colorama-0.4.6 decorator-5.2.1 executing-2.2.0 ipython-8.12.3 jedi-0.19.2 parso-0.8.4 pexpect-4.9.0 pickleshare-0.7.5 prompt-toolkit-3.0.50 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.19.1 stack-data-0.6.3 wcwidth-0.2.13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n my_env pip uninstall torch torchvision xformers -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LzP8GNxX4k9",
        "outputId": "d5a26676-02f2-4e21-de7f-389b8a4e4f56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.4.1\n",
            "Uninstalling torch-2.4.1:\n",
            "  Successfully uninstalled torch-2.4.1\n",
            "Found existing installation: torchvision 0.13.0+cu113\n",
            "Uninstalling torchvision-0.13.0+cu113:\n",
            "  Successfully uninstalled torchvision-0.13.0+cu113\n",
            "Found existing installation: xformers 0.0.28.post1\n",
            "Uninstalling xformers-0.0.28.post1:\n",
            "  Successfully uninstalled xformers-0.0.28.post1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n my_env pip install torch==1.12.0+cu113 torchvision==0.13.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHuWfQkdX7BP",
        "outputId": "9c1322cc-ec02-45a1-b327-9a00e2b41fa2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.12.0+cu113\n",
            "  Using cached https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp38-cp38-linux_x86_64.whl (1837.6 MB)\n",
            "Collecting torchvision==0.13.0+cu113\n",
            "  Using cached https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp38-cp38-linux_x86_64.whl (23.4 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/my_env/lib/python3.8/site-packages (from torch==1.12.0+cu113) (4.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/my_env/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/envs/my_env/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/envs/my_env/lib/python3.8/site-packages (from torchvision==0.13.0+cu113) (9.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/envs/my_env/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/my_env/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/envs/my_env/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/my_env/lib/python3.8/site-packages (from requests->torchvision==0.13.0+cu113) (2025.1.31)\n",
            "Installing collected packages: torch, torchvision\n",
            "Successfully installed torch-1.12.0+cu113 torchvision-0.13.0+cu113\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load dinomaly_mvtec_sep.py\n",
        "%%writefile dinomaly_mvtec_sep.py\n",
        "\n",
        "# This is a sample Python script.\n",
        "\n",
        "# Press ⌃R to execute it or replace it with your code.\n",
        "# Press Double ⇧ to search everywhere for classes, files, tool windows, actions, and settings.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from dataset import get_data_transforms, get_strong_transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "from models.uad import ViTill, ViTillv2\n",
        "from models import vit_encoder\n",
        "from dinov1.utils import trunc_normal_\n",
        "from models.vision_transformer import Block as VitBlock, bMlp, Attention, LinearAttention, \\\n",
        "    LinearAttention2\n",
        "from dataset import MVTecDataset\n",
        "import torch.backends.cudnn as cudnn\n",
        "import argparse\n",
        "from utils import evaluation_batch, global_cosine, replace_layers, global_cosine_hm_percent, WarmCosineScheduler\n",
        "from torch.nn import functional as F\n",
        "from functools import partial\n",
        "from ptflops import get_model_complexity_info\n",
        "from optimizers import StableAdamW\n",
        "import warnings\n",
        "import copy\n",
        "import logging\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "class BatchNorm1d(nn.BatchNorm1d):\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = super(BatchNorm1d, self).forward(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_logger(name, save_path=None, level='INFO'):\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(getattr(logging, level))\n",
        "\n",
        "    log_format = logging.Formatter('%(message)s')\n",
        "    streamHandler = logging.StreamHandler()\n",
        "    streamHandler.setFormatter(log_format)\n",
        "    logger.addHandler(streamHandler)\n",
        "\n",
        "    if not save_path is None:\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        fileHandler = logging.FileHandler(os.path.join(save_path, 'log.txt'))\n",
        "        fileHandler.setFormatter(log_format)\n",
        "        logger.addHandler(fileHandler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def train(item):\n",
        "    start_time = time.time()\n",
        "\n",
        "    setup_seed(1)\n",
        "    print_fn(item)\n",
        "    # total_iters = 5000\n",
        "    total_iters= 1000\n",
        "    # batch_size = 16\n",
        "    batch_size = 16\n",
        "    # image_size = 448\n",
        "    image_size = 224\n",
        "    # crop_size = 392\n",
        "    crop_size = 224\n",
        "\n",
        "    print(\"----------------------------------------------------------------------------------------------\")\n",
        "    print_fn(f\"[PARAMS] total_iters={total_iters}, batch_size={batch_size}, image_size={image_size}, crop_size={crop_size}\")\n",
        "    print(\"----------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "    data_transform, gt_transform = get_data_transforms(image_size, crop_size)\n",
        "\n",
        "    train_path = os.path.join(args.data_path, item, 'train')\n",
        "    test_path = os.path.join(args.data_path, item)\n",
        "\n",
        "    train_data = ImageFolder(root=train_path, transform=data_transform)\n",
        "    test_data = MVTecDataset(root=test_path, transform=data_transform, gt_transform=gt_transform, phase=\"test\")\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4,\n",
        "                                                   drop_last=True)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    # encoder_name = 'dinov2reg_vit_small_14'\n",
        "    encoder_name = 'dinov2reg_vit_base_14'\n",
        "    # encoder_name = 'dinov2reg_vit_large_14'\n",
        "\n",
        "\n",
        "    # target_layers = [4, 5, 6, 7, 8, 9, 10, 11] # focus deep layer . don't try again because it makes model worse.\n",
        "    target_layers = [2, 3, 4, 5, 6, 7, 8, 9]\n",
        "    fuse_layer_encoder = [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
        "    fuse_layer_decoder = [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
        "    # target_layers = list(range(4, 19))\n",
        "\n",
        "    encoder = vit_encoder.load(encoder_name)\n",
        "\n",
        "    if 'small' in encoder_name:\n",
        "        embed_dim, num_heads = 384, 6\n",
        "    elif 'base' in encoder_name:\n",
        "        embed_dim, num_heads = 768, 12\n",
        "    elif 'large' in encoder_name:\n",
        "        embed_dim, num_heads = 1024, 16\n",
        "        target_layers = [4, 6, 8, 10, 12, 14, 16, 18]\n",
        "    else:\n",
        "        raise \"Architecture not in small, base, large.\"\n",
        "\n",
        "    bottleneck = []\n",
        "    decoder = []\n",
        "\n",
        "    bottleneck.append(bMlp(embed_dim, embed_dim * 4, embed_dim, drop=0.2))\n",
        "    bottleneck = nn.ModuleList(bottleneck)\n",
        "\n",
        "    for i in range(8):\n",
        "        blk = VitBlock(dim=embed_dim, num_heads=num_heads, mlp_ratio=4.,\n",
        "                       qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-8), attn_drop=0.,\n",
        "                       attn=LinearAttention2)\n",
        "        decoder.append(blk)\n",
        "    decoder = nn.ModuleList(decoder)\n",
        "\n",
        "    # model = ViTill(encoder=encoder, bottleneck=bottleneck, decoder=decoder, target_layers=target_layers,\n",
        "    #                mask_neighbor_size=0, fuse_layer_encoder=fuse_layer_encoder, fuse_layer_decoder=fuse_layer_decoder)\n",
        "    model = ViTill(encoder=encoder, bottleneck=bottleneck, decoder=decoder, target_layers=target_layers,\n",
        "                   mask_neighbor_size=1, fuse_layer_encoder=fuse_layer_encoder, fuse_layer_decoder=fuse_layer_decoder)\n",
        "    model = model.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    trainable = nn.ModuleList([bottleneck, decoder])\n",
        "\n",
        "    for m in trainable.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=0.01, a=-0.03, b=0.03)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    optimizer = StableAdamW([{'params': trainable.parameters()}],\n",
        "                            lr=2e-3, betas=(0.9, 0.999), weight_decay=1e-4, amsgrad=True, eps=1e-8)\n",
        "    # lr_scheduler = WarmCosineScheduler(optimizer, base_value=2e-3, final_value=2e-4, total_iters=total_iters,\n",
        "    #                                    warmup_iters=100)\n",
        "    lr_scheduler = WarmCosineScheduler(optimizer, base_value=1e-3, final_value=3e-4, total_iters=total_iters,\n",
        "                                       warmup_iters=100)\n",
        "\n",
        "    print_fn('train image number:{}'.format(len(train_data)))\n",
        "\n",
        "    it = 0\n",
        "    for epoch in range(int(np.ceil(total_iters / len(train_dataloader)))):\n",
        "        model.train()\n",
        "\n",
        "        loss_list = []\n",
        "        for img, label in train_dataloader:\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            en, de = model(img)\n",
        "\n",
        "            # p_final = 0.9\n",
        "            p_final = 0.85\n",
        "            p = min(p_final * it / 1000, p_final)\n",
        "            # loss = global_cosine_hm_percent(en, de, p=p, factor=0.1)\n",
        "            loss = global_cosine_hm_percent(en, de, p=p, factor=0.2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm(trainable.parameters(), max_norm=0.1)\n",
        "\n",
        "            optimizer.step()\n",
        "            loss_list.append(loss.item())\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            if (it + 1) % 5000 == 0 or it == total_iters - 1:\n",
        "                # results = evaluation_batch(model, test_dataloader, device, max_ratio=0.01, resize_mask=256)\n",
        "                results = evaluation_batch(model, test_dataloader, device, max_ratio=0.01, resize_mask=224)\n",
        "                auroc_sp, ap_sp, f1_sp, auroc_px, ap_px, f1_px, aupro_px = results\n",
        "\n",
        "                print_fn(\n",
        "                    '{}: I-Auroc:{:.4f}, I-AP:{:.4f}, I-F1:{:.4f}, P-AUROC:{:.4f}, P-AP:{:.4f}, P-F1:{:.4f}, P-AUPRO:{:.4f}'.format(\n",
        "                        item, auroc_sp, ap_sp, f1_sp, auroc_px, ap_px, f1_px, aupro_px))\n",
        "                model.train()\n",
        "\n",
        "            it += 1\n",
        "            if it == total_iters:\n",
        "                break\n",
        "            if (it + 1) % 100 == 0:\n",
        "                print_fn('iter [{}/{}], loss:{:.4f}'.format(it, total_iters, np.mean(loss_list)))\n",
        "                loss_list = []\n",
        "\n",
        "    # torch.save(model.state_dict(), os.path.join(args.save_dir, args.save_name, 'model.pth'))\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    minutes, seconds = divmod(elapsed_time, 60)\n",
        "    print_fn(f\"[TIME] Training time for {item}: {int(minutes)}m {int(seconds)}s\")\n",
        "\n",
        "    return auroc_sp, ap_sp, f1_sp, auroc_px, ap_px, f1_px, aupro_px\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='')\n",
        "    parser.add_argument('--data_path', type=str, default='../mvtec_anomaly_detection')\n",
        "    parser.add_argument('--save_dir', type=str, default='./saved_results')\n",
        "    parser.add_argument('--save_name', type=str,\n",
        "                        default='vitill_mvtec_sep_dinov2br_c392_en29_bn4dp2_de8_elaelu_md2_i1_it10k_sadm2e3_wd1e4_w1hcosa_ghmp09f01w1k_b16_ev_s1')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # item_list = ['carpet', 'grid', 'leather', 'tile', 'wood', 'bottle', 'cable', 'capsule',\n",
        "    #              'hazelnut', 'metal_nut', 'pill', 'screw', 'toothbrush', 'transistor', 'zipper']\n",
        "    item_list = ['wood']\n",
        "    logger = get_logger(args.save_name, os.path.join(args.save_dir, args.save_name))\n",
        "    print_fn = logger.info\n",
        "\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    print_fn(device)\n",
        "\n",
        "    result_list = []\n",
        "    for i, item in enumerate(item_list):\n",
        "        auroc_sp, ap_sp, f1_sp, auroc_px, ap_px, f1_px, aupro_px = train(item)\n",
        "        result_list.append([item, auroc_sp, ap_sp, f1_sp, auroc_px, ap_px, f1_px, aupro_px])\n",
        "\n",
        "    mean_auroc_sp = np.mean([result[1] for result in result_list])\n",
        "    mean_ap_sp = np.mean([result[2] for result in result_list])\n",
        "    mean_f1_sp = np.mean([result[3] for result in result_list])\n",
        "\n",
        "    mean_auroc_px = np.mean([result[4] for result in result_list])\n",
        "    mean_ap_px = np.mean([result[5] for result in result_list])\n",
        "    mean_f1_px = np.mean([result[6] for result in result_list])\n",
        "    mean_aupro_px = np.mean([result[7] for result in result_list])\n",
        "\n",
        "    print_fn(result_list)\n",
        "    print_fn(\n",
        "        'Mean: I-Auroc:{:.4f}, I-AP:{:.4f}, I-F1:{:.4f}, P-AUROC:{:.4f}, P-AP:{:.4f}, P-F1:{:.4f}, P-AUPRO:{:.4f}'.format(\n",
        "            mean_auroc_sp, mean_ap_sp, mean_f1_sp,\n",
        "            mean_auroc_px, mean_ap_px, mean_f1_px, mean_aupro_px))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYn9mij0Y74d",
        "outputId": "8ed6ebd0-5718-48eb-909e-0b54aa353c84"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dinomaly_mvtec_sep.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load dataset.py\n",
        "%%writefile dataset.py\n",
        "import random\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import glob\n",
        "from torchvision.datasets import MNIST, CIFAR10, FashionMNIST, ImageFolder\n",
        "import numpy as np\n",
        "import torch.multiprocessing\n",
        "import json\n",
        "\n",
        "# import imgaug.augmenters as iaa\n",
        "# from perlin import rand_perlin_2d_np\n",
        "\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "\n",
        "\n",
        "def get_data_transforms(size, isize, mean_train=None, std_train=None):\n",
        "    mean_train = [0.485, 0.456, 0.406] if mean_train is None else mean_train\n",
        "    std_train = [0.229, 0.224, 0.225] if std_train is None else std_train\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.convert(\"RGB\")), ## added for 3 channel (input image:RGB)\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.CenterCrop(isize),\n",
        "        transforms.Normalize(mean=mean_train,\n",
        "                             std=std_train)])\n",
        "    gt_transforms = transforms.Compose([\n",
        "        transforms.Lambda(lambda img: img.convert(\"L\")), # added for mask image: grayscale 1-channel\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.CenterCrop(isize),\n",
        "        transforms.ToTensor()])\n",
        "    return data_transforms, gt_transforms\n",
        "\n",
        "\n",
        "def get_strong_transforms(size, isize, mean_train=None, std_train=None):\n",
        "    mean_train = [0.485, 0.456, 0.406] if mean_train is None else mean_train\n",
        "    std_train = [0.229, 0.224, 0.225] if std_train is None else std_train\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.Resize((size, size)),\n",
        "        transforms.RandomResizedCrop((isize, isize), scale=(0.6, 1.1)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(0.1, 0.1, 0.1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean_train,\n",
        "                             std=std_train)])\n",
        "    return data_transforms\n",
        "\n",
        "\n",
        "class MVTecDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform, gt_transform, phase):\n",
        "        if phase == 'train':\n",
        "            self.img_path = os.path.join(root, 'train')\n",
        "        else:\n",
        "            self.img_path = os.path.join(root, 'test')\n",
        "            self.gt_path = os.path.join(root, 'ground_truth')\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "        # load dataset\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "        self.cls_idx = 0\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        gt_tot_paths = []\n",
        "        tot_labels = []\n",
        "        tot_types = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.JPG\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.bmp\")\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend([0] * len(img_paths))\n",
        "                tot_labels.extend([0] * len(img_paths))\n",
        "                tot_types.extend(['good'] * len(img_paths))\n",
        "            else:\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.JPG\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.bmp\")\n",
        "                gt_paths = glob.glob(os.path.join(self.gt_path, defect_type) + \"/*.png\")\n",
        "                img_paths.sort()\n",
        "                gt_paths.sort()\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend(gt_paths)\n",
        "                tot_labels.extend([1] * len(img_paths))\n",
        "                tot_types.extend([defect_type] * len(img_paths))\n",
        "\n",
        "        assert len(img_tot_paths) == len(gt_tot_paths), \"Something wrong with test and ground truth pair!\"\n",
        "\n",
        "        return np.array(img_tot_paths), np.array(gt_tot_paths), np.array(tot_labels), np.array(tot_types)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        if label == 0:\n",
        "            gt = torch.zeros([1, img.size()[-2], img.size()[-2]])\n",
        "        else:\n",
        "            gt = Image.open(gt)\n",
        "            gt = self.gt_transform(gt)\n",
        "\n",
        "        assert img.size()[1:] == gt.size()[1:], \"image.size != gt.size !!!\"\n",
        "\n",
        "        return img, gt, label, img_path\n",
        "\n",
        "\n",
        "class RealIADDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, category, transform, gt_transform, phase):\n",
        "        self.img_path = os.path.join(root, 'realiad_1024', category)\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.phase = phase\n",
        "\n",
        "        json_path = os.path.join(root, 'realiad_jsons', 'realiad_jsons', category + '.json')\n",
        "        with open(json_path) as file:\n",
        "            class_json = file.read()\n",
        "        class_json = json.loads(class_json)\n",
        "\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = [], [], [], []\n",
        "\n",
        "        data_set = class_json[phase]\n",
        "        for sample in data_set:\n",
        "            self.img_paths.append(os.path.join(root, 'realiad_1024', category, sample['image_path']))\n",
        "            label = sample['anomaly_class'] != 'OK'\n",
        "            if label:\n",
        "                self.gt_paths.append(os.path.join(root, 'realiad_1024', category, sample['mask_path']))\n",
        "            else:\n",
        "                self.gt_paths.append(None)\n",
        "            self.labels.append(label)\n",
        "            self.types.append(sample['anomaly_class'])\n",
        "\n",
        "        self.img_paths = np.array(self.img_paths)\n",
        "        self.gt_paths = np.array(self.gt_paths)\n",
        "        self.labels = np.array(self.labels)\n",
        "        self.types = np.array(self.types)\n",
        "        self.cls_idx = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        if self.phase == 'train':\n",
        "            return img, label\n",
        "\n",
        "        if label == 0:\n",
        "            gt = torch.zeros([1, img.size()[-2], img.size()[-2]])\n",
        "        else:\n",
        "            gt = Image.open(gt)\n",
        "            gt = self.gt_transform(gt)\n",
        "\n",
        "        assert img.size()[1:] == gt.size()[1:], \"image.size != gt.size !!!\"\n",
        "\n",
        "        return img, gt, label, img_path\n",
        "\n",
        "\n",
        "class LOCODataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform, gt_transform, phase):\n",
        "        if phase == 'train':\n",
        "            self.img_path = os.path.join(root, 'train')\n",
        "        else:\n",
        "            self.img_path = os.path.join(root, 'test')\n",
        "            self.gt_path = os.path.join(root, 'ground_truth')\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "        # load dataset\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        gt_tot_paths = []\n",
        "        tot_labels = []\n",
        "        tot_types = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\")\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend([0] * len(img_paths))\n",
        "                tot_labels.extend([0] * len(img_paths))\n",
        "                tot_types.extend(['good'] * len(img_paths))\n",
        "            else:\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\")\n",
        "                gt_paths = glob.glob(os.path.join(self.gt_path, defect_type) + \"/*/000.png\")\n",
        "                img_paths.sort()\n",
        "                gt_paths.sort()\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend(gt_paths)\n",
        "                tot_labels.extend([1] * len(img_paths))\n",
        "                tot_types.extend([defect_type] * len(img_paths))\n",
        "\n",
        "        assert len(img_tot_paths) == len(gt_tot_paths), \"Something wrong with test and ground truth pair!\"\n",
        "\n",
        "        return img_tot_paths, gt_tot_paths, tot_labels, tot_types\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        size = (img.size[1], img.size[0])\n",
        "        img = self.transform(img)\n",
        "        type = self.types[idx]\n",
        "        if gt == 0:\n",
        "            gt = torch.zeros([1, img.size()[-2], img.size()[-2]])\n",
        "        else:\n",
        "            gt = Image.open(gt)\n",
        "            gt = self.gt_transform(gt)\n",
        "\n",
        "        assert img.size()[1:] == gt.size()[1:], \"image.size != gt.size !!!\"\n",
        "\n",
        "        return img, gt, label, img_path, type, size\n",
        "\n",
        "\n",
        "class InsPLADDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform, phase):\n",
        "        if phase == 'train':\n",
        "            self.img_path = os.path.join(root, 'train')\n",
        "        else:\n",
        "            self.img_path = os.path.join(root, 'test')\n",
        "        self.transform = transform\n",
        "        self.phase = phase\n",
        "        # load dataset\n",
        "        self.img_paths, self.labels = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        tot_labels = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*\")\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                tot_labels.extend([0] * len(img_paths))\n",
        "            else:\n",
        "                if self.phase == 'train':\n",
        "                    continue\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*\")\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                tot_labels.extend([1] * len(img_paths))\n",
        "\n",
        "        return img_tot_paths, tot_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.img_paths[idx], self.labels[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img, label, img_path\n",
        "\n",
        "\n",
        "class AeBADDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform, gt_transform, phase):\n",
        "        if phase == 'train':\n",
        "            self.img_path = os.path.join(root, 'train')\n",
        "        else:\n",
        "            self.img_path = os.path.join(root, 'test')\n",
        "            self.gt_path = os.path.join(root, 'ground_truth')\n",
        "        self.phase = phase\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "        # load dataset\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        gt_tot_paths = []\n",
        "        tot_labels = []\n",
        "        tot_types = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "        defect_types = [i for i in defect_types if i[0] != '.']\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                domain_types = os.listdir(os.path.join(self.img_path, defect_type))\n",
        "                domain_types = [i for i in domain_types if i[0] != '.']\n",
        "\n",
        "                for domain_type in domain_types:\n",
        "                    img_paths = glob.glob(os.path.join(self.img_path, defect_type, domain_type) + \"/*.png\")\n",
        "                    img_tot_paths.extend(img_paths)\n",
        "                    gt_tot_paths.extend([0] * len(img_paths))\n",
        "                    tot_labels.extend([0] * len(img_paths))\n",
        "                    tot_types.extend(['good'] * len(img_paths))\n",
        "            else:\n",
        "                domain_types = os.listdir(os.path.join(self.img_path, defect_type))\n",
        "                domain_types = [i for i in domain_types if i[0] != '.']\n",
        "\n",
        "                for domain_type in domain_types:\n",
        "                    img_paths = glob.glob(os.path.join(self.img_path, defect_type, domain_type) + \"/*.png\")\n",
        "                    gt_paths = glob.glob(os.path.join(self.gt_path, defect_type, domain_type) + \"/*.png\")\n",
        "                    img_paths.sort()\n",
        "                    gt_paths.sort()\n",
        "                    img_tot_paths.extend(img_paths)\n",
        "                    gt_tot_paths.extend(gt_paths)\n",
        "                    tot_labels.extend([1] * len(img_paths))\n",
        "                    tot_types.extend([defect_type] * len(img_paths))\n",
        "\n",
        "        assert len(img_tot_paths) == len(gt_tot_paths), \"Something wrong with test and ground truth pair!\"\n",
        "\n",
        "        return img_tot_paths, gt_tot_paths, tot_labels, tot_types\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        if self.phase == 'train':\n",
        "            return img, label\n",
        "        if gt == 0:\n",
        "            gt = torch.zeros([1, img.size()[-2], img.size()[-2]])\n",
        "        else:\n",
        "            gt = Image.open(gt)\n",
        "            gt = self.gt_transform(gt)\n",
        "\n",
        "        assert img.size()[1:] == gt.size()[1:], \"image.size != gt.size !!!\"\n",
        "\n",
        "        return img, gt, label, img_path\n",
        "\n",
        "\n",
        "class MiniDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "\n",
        "        self.img_path = root\n",
        "        self.transform = transform\n",
        "        # load dataset\n",
        "        self.img_paths, self.labels = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        tot_labels = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*\")\n",
        "            img_tot_paths.extend(img_paths)\n",
        "            tot_labels.extend([1] * len(img_paths))\n",
        "\n",
        "        return img_tot_paths, tot_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            img_path, label = self.img_paths[idx], self.labels[idx]\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "        except:\n",
        "            img_path, label = self.img_paths[idx - 1], self.labels[idx - 1]\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "class MVTecDRAEMDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform, gt_transform, strong_transform, phase, anomaly_source_path, anomaly_ratio=0.5,\n",
        "                 size=256):\n",
        "        if phase == 'train':\n",
        "            self.img_path = os.path.join(root, 'train')\n",
        "        else:\n",
        "            self.img_path = os.path.join(root, 'test')\n",
        "            self.gt_path = os.path.join(root, 'ground_truth')\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "        self.strong_transform = strong_transform\n",
        "        self.anomaly_ratio = anomaly_ratio\n",
        "        self.size = size\n",
        "        # load dataset\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "        self.anomaly_source_paths = sorted(glob.glob(anomaly_source_path + \"/*/*.jpg\"))\n",
        "\n",
        "        self.augmenters = [iaa.GammaContrast((0.5, 2.0), per_channel=True),\n",
        "                           iaa.MultiplyAndAddToBrightness(mul=(0.8, 1.2), add=(-30, 30)),\n",
        "                           iaa.pillike.EnhanceSharpness(),\n",
        "                           iaa.AddToHueAndSaturation((-50, 50), per_channel=True),\n",
        "                           iaa.Solarize(0.5, threshold=(32, 128)),\n",
        "                           iaa.Posterize(),\n",
        "                           iaa.Invert(),\n",
        "                           iaa.pillike.Autocontrast(),\n",
        "                           iaa.pillike.Equalize(),\n",
        "                           iaa.Affine(rotate=(-45, 45))\n",
        "                           ]\n",
        "\n",
        "        self.rot = iaa.Sequential([iaa.Affine(rotate=(-90, 90))])\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        gt_tot_paths = []\n",
        "        tot_labels = []\n",
        "        tot_types = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.JPG\")\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend([0] * len(img_paths))\n",
        "                tot_labels.extend([0] * len(img_paths))\n",
        "                tot_types.extend(['good'] * len(img_paths))\n",
        "            else:\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.JPG\")\n",
        "                gt_paths = glob.glob(os.path.join(self.gt_path, defect_type) + \"/*.png\")\n",
        "                img_paths.sort()\n",
        "                gt_paths.sort()\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend(gt_paths)\n",
        "                tot_labels.extend([1] * len(img_paths))\n",
        "                tot_types.extend([defect_type] * len(img_paths))\n",
        "\n",
        "        assert len(img_tot_paths) == len(gt_tot_paths), \"Something wrong with test and ground truth pair!\"\n",
        "\n",
        "        return img_tot_paths, gt_tot_paths, tot_labels, tot_types\n",
        "\n",
        "    def randAugmenter(self):\n",
        "        aug_ind = np.random.choice(np.arange(len(self.augmenters)), 3, replace=False)\n",
        "        aug = iaa.Sequential([self.augmenters[aug_ind[0]],\n",
        "                              self.augmenters[aug_ind[1]],\n",
        "                              self.augmenters[aug_ind[2]]]\n",
        "                             )\n",
        "        return aug\n",
        "\n",
        "    def augment_image(self, image, anomaly_source_path):\n",
        "        no_anomaly = random.random()\n",
        "        if no_anomaly > self.anomaly_ratio:\n",
        "            return image, 0\n",
        "        else:\n",
        "            aug = self.randAugmenter()\n",
        "\n",
        "            perlin_scale = 6\n",
        "            min_perlin_scale = 0\n",
        "            anomaly_source_img = Image.open(anomaly_source_path).convert('RGB').resize((self.size, self.size))\n",
        "            anomaly_source_img = np.asarray(anomaly_source_img)\n",
        "            anomaly_img_augmented = aug(image=anomaly_source_img)\n",
        "\n",
        "            perlin_scalex = 2 ** (torch.randint(min_perlin_scale, perlin_scale, (1,)).numpy()[0])\n",
        "            perlin_scaley = 2 ** (torch.randint(min_perlin_scale, perlin_scale, (1,)).numpy()[0])\n",
        "\n",
        "            perlin_noise = rand_perlin_2d_np((self.size, self.size),\n",
        "                                             (perlin_scalex, perlin_scaley))\n",
        "            perlin_noise = self.rot(image=perlin_noise)\n",
        "            threshold = 0.5\n",
        "            perlin_thr = np.where(perlin_noise > threshold, np.ones_like(perlin_noise), np.zeros_like(perlin_noise))\n",
        "            perlin_thr = np.expand_dims(perlin_thr, axis=2)\n",
        "\n",
        "            img_thr = anomaly_img_augmented.astype(np.float32) * perlin_thr\n",
        "\n",
        "            beta = random.random() * 0.7 + 0.1\n",
        "\n",
        "            image = image.resize((self.size, self.size))\n",
        "            image = np.asarray(image)\n",
        "            augmented_image = image * (1 - perlin_thr) + (1 - beta) * img_thr + beta * image * (perlin_thr)\n",
        "            # augmented_image = augmented_image.astype(np.float32)\n",
        "            msk = (perlin_thr).astype(np.float32)\n",
        "            augmented_image = msk * augmented_image + (1 - msk) * image\n",
        "\n",
        "            return Image.fromarray(np.uint8(augmented_image)), 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        anomaly_source_idx = torch.randint(0, len(self.anomaly_source_paths), (1,)).item()\n",
        "        a_img, label = self.augment_image(img, self.anomaly_source_paths[anomaly_source_idx])\n",
        "\n",
        "        img = self.transform(img)\n",
        "        a_img = self.strong_transform(a_img)\n",
        "\n",
        "        assert img.size()[1:] == a_img.size()[1:], \"image.size != a_img.size !!!\"\n",
        "\n",
        "        return img, a_img, label\n",
        "\n",
        "\n",
        "class MVTecSimplexDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform, gt_transform, phase):\n",
        "        if phase == 'train':\n",
        "            self.img_path = os.path.join(root, 'train')\n",
        "        else:\n",
        "            self.img_path = os.path.join(root, 'test')\n",
        "            self.gt_path = os.path.join(root, 'ground_truth')\n",
        "        self.transform = transform\n",
        "        self.gt_transform = gt_transform\n",
        "\n",
        "        self.simplexNoise = Simplex_CLASS()\n",
        "        # load dataset\n",
        "        self.img_paths, self.gt_paths, self.labels, self.types = self.load_dataset()  # self.labels => good : 0, anomaly : 1\n",
        "\n",
        "    def load_dataset(self):\n",
        "\n",
        "        img_tot_paths = []\n",
        "        gt_tot_paths = []\n",
        "        tot_labels = []\n",
        "        tot_types = []\n",
        "\n",
        "        defect_types = os.listdir(self.img_path)\n",
        "\n",
        "        for defect_type in defect_types:\n",
        "            if defect_type == 'good':\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.JPG\")\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend([0] * len(img_paths))\n",
        "                tot_labels.extend([0] * len(img_paths))\n",
        "                tot_types.extend(['good'] * len(img_paths))\n",
        "            else:\n",
        "                img_paths = glob.glob(os.path.join(self.img_path, defect_type) + \"/*.png\") + \\\n",
        "                            glob.glob(os.path.join(self.img_path, defect_type) + \"/*.JPG\")\n",
        "                gt_paths = glob.glob(os.path.join(self.gt_path, defect_type) + \"/*.png\")\n",
        "                img_paths.sort()\n",
        "                gt_paths.sort()\n",
        "                img_tot_paths.extend(img_paths)\n",
        "                gt_tot_paths.extend(gt_paths)\n",
        "                tot_labels.extend([1] * len(img_paths))\n",
        "                tot_types.extend([defect_type] * len(img_paths))\n",
        "\n",
        "        assert len(img_tot_paths) == len(gt_tot_paths), \"Something wrong with test and ground truth pair!\"\n",
        "\n",
        "        return img_tot_paths, gt_tot_paths, tot_labels, tot_types\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, gt, label, img_type = self.img_paths[idx], self.gt_paths[idx], self.labels[idx], self.types[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img_normal = self.transform(img)\n",
        "\n",
        "        if random.random() > 0.5:\n",
        "            return img_normal, img_normal\n",
        "        ## simplex_noise\n",
        "        size = 256\n",
        "        img = img.resize((size, size))\n",
        "        img = np.asarray(img)\n",
        "        h_noise = np.random.randint(10, int(size // 8))\n",
        "        w_noise = np.random.randint(10, int(size // 8))\n",
        "        start_h_noise = np.random.randint(1, size - h_noise)\n",
        "        start_w_noise = np.random.randint(1, size - w_noise)\n",
        "        noise_size = (h_noise, w_noise)\n",
        "        simplex_noise = self.simplexNoise.rand_3d_octaves((3, *noise_size), 6, 0.6)\n",
        "        init_zero = np.zeros((256, 256, 3))\n",
        "        init_zero[start_h_noise: start_h_noise + h_noise, start_w_noise: start_w_noise + w_noise,\n",
        "        :] = 0.2 * simplex_noise.transpose(1, 2, 0)\n",
        "        img_noise = img + init_zero * 255\n",
        "        img_noise = Image.fromarray(np.uint8(img_noise))\n",
        "        img_noise = self.transform(img_noise)\n",
        "\n",
        "        return img_normal, img_noise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXw4an3HfLUn",
        "outputId": "66ae5357-7280-40cc-c5f4-2280c5baa6e5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZczeJNUuZdWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf backbones"
      ],
      "metadata": {
        "id": "pRJb1EtRbz8r"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf saved_results"
      ],
      "metadata": {
        "id": "F6_6UZjtb1xh"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n my_env python dinomaly_mvtec_sep.py --data_path /content/drive/MyDrive/dinomaly_11_04_2025/Dinomaly/mvtec_anomaly_detection/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZQ5hww0UXww",
        "outputId": "836ae537-dc0b-44b7-eb70-953f8b729cfa"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------------------------\n",
            "\n",
            "/content/drive/MyDrive/dinomaly_11_04_2025/Dinomaly/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
            "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
            "/content/drive/MyDrive/dinomaly_11_04_2025/Dinomaly/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
            "  warnings.warn(\"xFormers is not available (Attention)\")\n",
            "/content/drive/MyDrive/dinomaly_11_04_2025/Dinomaly/dinov2/layers/block.py:38: UserWarning: xFormers is not available (Block)\n",
            "  warnings.warn(\"xFormers is not available (Block)\")\n",
            "cuda:0\n",
            "wood\n",
            "[PARAMS] total_iters=1000, batch_size=16, image_size=224, crop_size=224\n",
            "\n",
            "  0%|          | 0.00/330M [00:00<?, ?B/s]\n",
            "  0%|          | 1.19M/330M [00:00<00:27, 12.4MB/s]\n",
            "  2%|▏         | 7.78M/330M [00:00<00:07, 45.7MB/s]\n",
            "  6%|▌         | 20.6M/330M [00:00<00:03, 86.3MB/s]\n",
            " 10%|█         | 34.5M/330M [00:00<00:02, 110MB/s] \n",
            " 15%|█▍        | 49.1M/330M [00:00<00:02, 125MB/s]\n",
            " 19%|█▉        | 63.6M/330M [00:00<00:02, 134MB/s]\n",
            " 24%|██▍       | 78.8M/330M [00:00<00:01, 142MB/s]\n",
            " 28%|██▊       | 94.1M/330M [00:00<00:01, 148MB/s]\n",
            " 33%|███▎      | 108M/330M [00:00<00:01, 122MB/s] \n",
            " 37%|███▋      | 121M/330M [00:01<00:01, 124MB/s]\n",
            " 41%|████      | 135M/330M [00:01<00:01, 132MB/s]\n",
            " 46%|████▌     | 150M/330M [00:01<00:01, 139MB/s]\n",
            " 50%|████▉     | 165M/330M [00:01<00:01, 143MB/s]\n",
            " 55%|█████▍    | 181M/330M [00:01<00:01, 149MB/s]\n",
            " 59%|█████▉    | 195M/330M [00:01<00:01, 138MB/s]\n",
            " 64%|██████▍   | 212M/330M [00:01<00:00, 148MB/s]\n",
            " 69%|██████▉   | 228M/330M [00:01<00:00, 154MB/s]\n",
            " 73%|███████▎  | 243M/330M [00:01<00:00, 145MB/s]\n",
            " 78%|███████▊  | 257M/330M [00:02<00:00, 139MB/s]\n",
            " 82%|████████▏ | 273M/330M [00:02<00:00, 146MB/s]\n",
            " 87%|████████▋ | 288M/330M [00:02<00:00, 149MB/s]\n",
            " 91%|█████████▏| 302M/330M [00:02<00:00, 134MB/s]\n",
            " 95%|█████████▌| 315M/330M [00:02<00:00, 124MB/s]\n",
            " 99%|█████████▉| 327M/330M [00:02<00:00, 120MB/s]\n",
            "100%|██████████| 330M/330M [00:02<00:00, 131MB/s]\n",
            "train image number:70\n",
            "iter [99/1000], loss:0.1062\n",
            "iter [199/1000], loss:0.0728\n",
            "iter [299/1000], loss:0.0609\n",
            "iter [399/1000], loss:0.0517\n",
            "iter [499/1000], loss:0.0447\n",
            "iter [599/1000], loss:0.0398\n",
            "iter [699/1000], loss:0.0360\n",
            "iter [799/1000], loss:0.0334\n",
            "iter [899/1000], loss:0.0316\n",
            "iter [999/1000], loss:0.0303\n",
            "wood: I-Auroc:0.8527, I-AP:0.7991, I-F1:0.8112, P-AUROC:0.9319, P-AP:0.2220, P-F1:0.3187, P-AUPRO:0.6566\n",
            "[TIME] Training time for wood: 17m 48s\n",
            "[['wood', 0.8527162977867204, 0.7990562365198213, 0.8111887611912594, 0.931851552585461, 0.22202801363017585, 0.318706442801435, 0.6565699173524762]]\n",
            "Mean: I-Auroc:0.8527, I-AP:0.7991, I-F1:0.8112, P-AUROC:0.9319, P-AP:0.2220, P-F1:0.3187, P-AUPRO:0.6566\n",
            "\n"
          ]
        }
      ]
    }
  ]
}